# ğŸš— Projeto: ClassificaÃ§Ã£o de Inadimplentes em EmprÃ©stimos de AutomÃ³veis

## ğŸ“Œ VisÃ£o Geral
Este projeto visa desenvolver um modelo de classificaÃ§Ã£o para identificar clientes inadimplentes em uma empresa de emprÃ©stimo de automÃ³veis. Atualmente, a anÃ¡lise Ã© feita manualmente, sendo demorada e imprecisa. Utilizaremos tÃ©cnicas de validaÃ§Ã£o de modelos e mÃ©tricas de avaliaÃ§Ã£o para criar uma soluÃ§Ã£o mais eficiente.

## Passos do Projeto

### ğŸ¤– 1. ClassificaÃ§Ã£o: ValidaÃ§Ã£o de Modelos e MÃ©tricas
**Objetivo**: Classificar clientes em adimplentes (0) e inadimplentes (1) usando dados histÃ³ricos.

### 2. Criando um Modelo Inicial
- Importamos bibliotecas e carregamos os dados
- Separamos os dados em features (X) e target (y)
- Utilizamos uma Ãrvore de DecisÃ£o como modelo inicial
- Avaliamos a acurÃ¡cia inicial (100%), indicando overfitting

### 3. Validando o Modelo
- Dividimos os dados em conjuntos de treino, validaÃ§Ã£o e teste:
  - 70% treino
  - 15% validaÃ§Ã£o
  - 15% teste
- Aplicamos estratificaÃ§Ã£o para manter proporÃ§Ã£o das classes
- Limitamos a profundidade da Ã¡rvore para reduzir overfitting

### AvaliaÃ§Ã£o de Performance
| MÃ©trica          | DescriÃ§Ã£o                                  | ImportÃ¢ncia               |
|------------------|--------------------------------------------|---------------------------|
| **Recall**       | IdentificaÃ§Ã£o real de inadimplentes        | Prioridade mÃ¡xima (risco) |
| **PrecisÃ£o**     | Minimizar falsos positivos                 | Custo operacional         |
| **F1-Score**     | EquilÃ­brio entre Recall/PrecisÃ£o           | MÃ©trica balanceada        |
| **AUC-ROC**      | Capacidade discriminativa geral            | â‰¥0.85 = Excelente         |

### 4. Avaliando o Modelo
- Utilizamos matriz de confusÃ£o para visualizar desempenho:
  - Verdadeiros Positivos (TP): Inadimplentes corretamente identificados
  - Falsos Positivos (FP): Adimplentes classificados como inadimplentes
  - Falsos Negativos (FN): Inadimplentes classificados como adimplentes
  - Verdadeiros Negativos (TN): Adimplentes corretamente identificados
 

###  TÃ©cnicas AvanÃ§adas Implementadas
| TÃ©cnica               | BenefÃ­cio                                  | ImplementaÃ§Ã£o             |
|-----------------------|--------------------------------------------|---------------------------|
| **KFold Estratificado** | ValidaÃ§Ã£o consistente em dados desbalanceados | `StratifiedKFold(n_splits=5)` |
| **SMOTE**             | Oversampling da classe minoritÃ¡ria         | `imblearn.over_sampling.SMOTE` |
| **Pipeline Integrado**| Processo reprodutÃ­vel de treino/inferÃªncia | `make_pipeline(SMOTE(), DecisionTreeClassifier(max_depth=5))` |

### 5. MÃ©tricas de AvaliaÃ§Ã£o
Principais mÃ©tricas utilizadas:
- **AcurÃ¡cia**: (TP + TN) / Total
- **PrecisÃ£o**: TP / (TP + FP) - Qualidade das previsÃµes positivas
- **Recall (Sensibilidade)**: TP / (TP + FN) - Capacidade de identificar positivos reais
- **F1-Score**: MÃ©dia harmÃ´nica entre precisÃ£o e recall
- **Curva ROC**: RelaÃ§Ã£o entre TPR (Recall) e FPR
- **AUC**: Ãrea sob a curva ROC

### 6. ValidaÃ§Ã£o Cruzada
**KFold**:
- Divide os dados em K partes (dobras)
- Treina K vezes com diferentes combinaÃ§Ãµes de treino/validaÃ§Ã£o
- Calcula mÃ©dias das mÃ©tricas

**EstratificaÃ§Ã£o**:
- MantÃ©m proporÃ§Ã£o de classes em cada dobra
- Especialmente importante para classes desbalanceadas

### 7. Balanceamento de Dados
**Problema**: Classe inadimplente Ã© minoritÃ¡ria
**SoluÃ§Ã£o**: Oversampling com SMOTE
- Gera amostras sintÃ©ticas da classe minoritÃ¡ria
- Cria pipeline com balanceamento e modelo

### 8. Testando o Modelo
- AvaliaÃ§Ã£o final no conjunto de teste separado inicialmente
- MÃ©tricas reportadas:
  - AcurÃ¡cia
  - PrecisÃ£o
  - Recall
  - F1-Score
  - AUC

## ğŸ“Š Resultados
O modelo final demonstrou:
- Alto recall para inadimplentes (identificaÃ§Ã£o de risco)
- Boa precisÃ£o para minimizar falsos positivos
- AUC > 0.85 indicando boa capacidade discriminativa

| Conjunto  | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score | AUC  |
|-----------|----------|----------|--------|----------|------|
| ValidaÃ§Ã£o | 0.92     | 0.87     | 0.83   | 0.85     | 0.89 |
| Teste     | 0.91     | 0.86     | 0.82   | 0.84     | 0.87 |


Insights Chave:

âœ… Recall de 82%+ - DetecÃ§Ã£o eficiente de clientes de risco 

âœ… PrecisÃ£o 86%+ - Minimiza impactos comerciais (falsos positivos) 

âœ… AUC >0.85 - Excelente capacidade discriminativa


## ğŸš€ Como Executar

### PrÃ©-requisitos
```bash
pip install -r requirements.txt
```
**requirements.txt**:
```
pandas==1.4.2
scikit-learn==1.1.1
imbalanced-learn==0.9.1
matplotlib==3.5.3
```

### ExecuÃ§Ã£o
1. Baixe o dataset (`emprestimos_automoveis.csv`)
2. Execute o notebook:
```bash
jupyter notebook "ClassificaÃ§Ã£o - ValidaÃ§Ã£o e mÃ©tricas.ipynb"
```

### Fluxo de Trabalho
```mermaid
graph TD
    A[Carregar Dados] --> B[DivisÃ£o Treino/Val/Teste]
    B --> C[Treinar Modelo Inicial]
    C --> D[Avaliar Overfitting]
    D --> E[AplicaÃ§Ã£o de SMOTE]
    E --> F[ValidaÃ§Ã£o Cruzada]
    F --> G[AvaliaÃ§Ã£o Final]
```

## ğŸ“… PrÃ³ximos Passos
- [ ] Teste com algoritmos avanÃ§ados (XGBoost, LightGBM)
- [ ] IntegraÃ§Ã£o com API REST para inferÃªncia em tempo real
- [ ] Painel de monitoramento contÃ­nuo de performance
- [ ] AnÃ¡lise de feature importance para otimizaÃ§Ã£o


## ğŸ’¡ Aprendizados Chave
```diff
+ ImportÃ¢ncia do balanceamento de classes em problemas reais
+ Trade-off entre recall e precisÃ£o em detecÃ§Ã£o de risco
+ ValidaÃ§Ã£o cruzada como prevenÃ§Ã£o contra overfitting
```

**Autor**: Jefferson Ferreira 

**Contato**: jfrancaferreira10@gmail.com 

**LinkedIn**: [meu-perfil](https://www.linkedin.com/in/jefferson-ferreira-ds/)  



